{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3pDokHMWzYO"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "e53b562b-3a1f-4592-ebb3-0ecb23aba3ac",
        "id": "a1W0b9g5fMOY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch_size:  64\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b181068fc2bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mcifar100_testset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar100_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#-----------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             raise RuntimeError('Dataset not found or corrupted.' +\n\u001b[1;32m     70\u001b[0m                                ' You can use download=True to download it')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m_check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcalculate_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from windowed_conv import Conv2d_window\n",
        "import matplotlib.pyplot as plt\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "\"\"\"import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='CIFAR100 training with 7x7 window in all layers and weight decay')\n",
        "parser.add_argument('--seed', default=None, type=int, help='rng seed')\n",
        "parser.add_argument('--n_layers', default=6, type=int, help='total number of conv layers')\n",
        "parser.add_argument('--save', type=str, default='/save_dir')\n",
        "\n",
        "args = parser.parse_args()\"\"\"\n",
        "\n",
        "# Fix seed\n",
        "\"\"\"if args.seed is not None:\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    warnings.warn('You have chosen to seed training. '\n",
        "                  'This will turn on the CUDNN deterministic setting, '\n",
        "                  'which can slow down your training considerably! '\n",
        "                  'You may see unexpected behavior when restarting '\n",
        "                  'from checkpoints.')\"\"\"\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "# Other useful definitions\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        shape=torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        return x.reshape(-1,shape) # batchsize-by-rest\n",
        "\n",
        "def makedirs(dirname):\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "\n",
        "makedirs(\"/save_dir\")\n",
        "\n",
        "CELoss=nn.CrossEntropyLoss()\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "# Define CIFAR100 dataloaders\n",
        "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.ToTensor()])\n",
        "transform_test=transforms.Compose([transforms.ToTensor()])\n",
        "data_path='/path_to_cifar100'\n",
        "batch_size=64\n",
        "print(\"Batch_size: \", batch_size)\n",
        "\n",
        "# Training data\n",
        "cifar100_trainset=datasets.CIFAR10(root=data_path, train=True, transform=transform_train, download=True)\n",
        "train_dl=torch.utils.data.DataLoader(cifar100_trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Validation data\n",
        "cifar100_testset=datasets.CIFAR10(root=data_path, train=False, transform=transform_test, download=True)\n",
        "test_dl=torch.utils.data.DataLoader(cifar100_testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "# Define the 2 models\n",
        "n_inp_ch=3 # CIFAR100\n",
        "n_out_ch=128\n",
        "n_out2_ch=256\n",
        "n_classes=100 # CIFAR100\n",
        "\n",
        "# Define networks\n",
        "n_layers=5  #< --altering part\n",
        "while n_layers < 15:\n",
        "\n",
        "  block=[]\n",
        "  block.append(torch.nn.Conv2d(n_inp_ch,n_out_ch,kernel_size=(3,3),stride=1,padding=(1,1),bias=False))\n",
        "  block.append(torch.nn.BatchNorm2d(n_out_ch))\n",
        "  block.append(torch.nn.ReLU())\n",
        "  block.append(torch.nn.Conv2d(n_out_ch,n_out2_ch,kernel_size=(3,3),padding=(1,1),bias=False))\n",
        "  block.append(torch.nn.BatchNorm2d(n_out2_ch))\n",
        "  block.append(torch.nn.ReLU()) #modified for testing 3x3 normal versus 7x7 hamming windowed\n",
        "\n",
        "  block_win=[]\n",
        "  block_win.append(Conv2d_window(n_inp_ch,n_out_ch,kernel_size=(7,7),stride=2,padding=(3,3),bias=False))\n",
        "  block_win.append(torch.nn.BatchNorm2d(n_out_ch))\n",
        "  block_win.append(torch.nn.ReLU())\n",
        "  block_win.append(Conv2d_window(n_out_ch,n_out2_ch,kernel_size=(7,7),padding=(3,3),bias=False))\n",
        "  block_win.append(torch.nn.BatchNorm2d(n_out2_ch))\n",
        "  block_win.append(torch.nn.ReLU())\n",
        "\n",
        "  if n_layers>2:\n",
        "      for i in range(n_layers-2):\n",
        "          block.append(torch.nn.Conv2d(n_out2_ch,n_out2_ch,kernel_size=(3,3),padding=(1,1),bias=False))\n",
        "          block.append(torch.nn.BatchNorm2d(n_out2_ch))\n",
        "          block.append(torch.nn.ReLU())\n",
        "\n",
        "          block_win.append(Conv2d_window(n_out2_ch,n_out2_ch,kernel_size=(7,7),padding=(3,3),bias=False))\n",
        "          block_win.append(torch.nn.BatchNorm2d(n_out2_ch))\n",
        "          block_win.append(torch.nn.ReLU())\n",
        "\n",
        "  model=torch.nn.Sequential(*block,torch.nn.AdaptiveAvgPool2d((1,1)),\\\n",
        "                Flatten(),torch.nn.Linear(n_out2_ch,n_classes)).to(device)\n",
        "\n",
        "  model_win=torch.nn.Sequential(*block_win,torch.nn.AdaptiveAvgPool2d((1,1)),\\\n",
        "                Flatten(),torch.nn.Linear(n_out2_ch,n_classes)).to(device)\n",
        "\n",
        "  #if n_layers>13:\n",
        "  #    warnings.warn(\"Networks deeper than 13 layers may not be ideal for small image sizes \"+\\\n",
        "  #             +\"(e.g. 32 x 32) and with the current width/pooling specifications\")\n",
        "  #-----------------------------------------------------------------------------------------------\n",
        "  # Define optimizer\n",
        "  optim=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9, weight_decay=0.001)\n",
        "  optim_win=torch.optim.SGD(model_win.parameters(),lr=0.01,momentum=0.9, weight_decay=0.001)\n",
        "  #-----------------------------------------------------------------------------------------------\n",
        "  # Training\n",
        "  loss_counter=0\n",
        "  log_loss=20 # track loss every 20 batches\n",
        "  n_epoch=50#150\n",
        "  #n_train_img=len(CIFAR10_trainset)\n",
        "  n_train_img=len(cifar100_trainset)\n",
        "\n",
        "  plot_loss=np.zeros(n_epoch*int(np.floor(np.ceil(n_train_img/batch_size)/log_loss)))\n",
        "  plot_loss_win=np.zeros(n_epoch*int(np.floor(np.ceil(n_train_img/batch_size)/log_loss)))\n",
        "\n",
        "  print(\"Totle number of Epochs:\", n_epoch)\n",
        "\n",
        "  for i_epoch in range(n_epoch):\n",
        "      print(\"Epoch: \", i_epoch)\n",
        "      batch_counter=0\n",
        "      running_loss=0\n",
        "      running_loss_win=0\n",
        "\n",
        "      # Learning rate decay\n",
        "      if i_epoch==75 or i_epoch==120:\n",
        "          for param_group in optim.param_groups:\n",
        "              param_group['lr']=0.1*param_group['lr']\n",
        "          for param_group in optim_win.param_groups:\n",
        "              param_group['lr']=0.1*param_group['lr']\n",
        "\n",
        "      for X,y in train_dl:\n",
        "          batch_counter+=1\n",
        "          # Train\n",
        "          X=X.to(device)\n",
        "          y=y.to(device)\n",
        "\n",
        "          # Backprop model 1\n",
        "          optim.zero_grad()\n",
        "          pred=model(X)\n",
        "          loss=CELoss(pred,y)\n",
        "          loss.backward()\n",
        "          optim.step()\n",
        "\n",
        "          # Backprop model 2\n",
        "          optim_win.zero_grad()\n",
        "          pred_win=model_win(X)\n",
        "          loss_win=CELoss(pred_win,y)\n",
        "          loss_win.backward()\n",
        "          optim_win.step()\n",
        "\n",
        "          running_loss+=loss.item()\n",
        "          running_loss_win+=loss_win.item()\n",
        "\n",
        "          if batch_counter%log_loss==0:\n",
        "              # print things\n",
        "              print(\"Batch_Counter: \", batch_counter)\n",
        "              print(np.argmax(pred[0,:].detach().cpu().numpy()),\\\n",
        "                    np.argmax(pred_win[0,:].detach().cpu().numpy()),\\\n",
        "                    y[0].detach().cpu().numpy())\n",
        "\n",
        "              # update loss trace\n",
        "              plot_loss[loss_counter]=running_loss\n",
        "              plot_loss_win[loss_counter]=running_loss_win\n",
        "              loss_counter+=1\n",
        "\n",
        "              running_loss=0\n",
        "              running_loss_win=0\n",
        "\n",
        "  # Plot losses\n",
        "  plt.figure(1)\n",
        "  plt.plot(plot_loss,label='conv')\n",
        "  plt.plot(plot_loss_win,label='conv_win')\n",
        "  plt.title('Losses')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(os.path.join(\"/save_dir\", 'loss_cifar100_all_win_wd_'+str(n_layers)+'_layers_'+str(None)+'.pdf'), bbox_inches='tight')\n",
        "\n",
        "  # Plot losses zoomed in\n",
        "  plt.figure(2)\n",
        "  plt.plot(plot_loss[-100:],label='conv')\n",
        "  plt.plot(plot_loss_win[-100:],label='conv_win')\n",
        "  plt.title('Zoomed Losses')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(os.path.join(\"/save_dir\", 'loss_zoom_cifar100_all_win_wd_'+str(n_layers)+'_layers_'+str(None)+'.pdf'), bbox_inches='tight')\n",
        "  #-----------------------------------------------------------------------------------------------\n",
        "  # Validation\n",
        "  accuracy=np.zeros(n_classes)\n",
        "  accuracy_win=np.zeros(n_classes)\n",
        "  class_counter=np.zeros(n_classes)\n",
        "\n",
        "  loss_counter=0\n",
        "  log_loss=20 # track loss every 20 batches\n",
        "  n_test_img=len(cifar100_testset)\n",
        "  #n_test_img=len(MNIST_testset)\n",
        "\n",
        "  plot_val_loss=np.zeros(int(np.floor(np.ceil(n_test_img/batch_size)/log_loss)))\n",
        "  plot_val_loss_win=np.zeros(int(np.floor(np.ceil(n_test_img/batch_size)/log_loss)))\n",
        "\n",
        "  print('Validating...')\n",
        "\n",
        "  batch_counter=0\n",
        "  running_loss=0\n",
        "  running_loss_win=0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      model_win.eval()\n",
        "\n",
        "      for X,y in test_dl:\n",
        "          # Test\n",
        "          batch_counter+=1\n",
        "          X=X.to(device)\n",
        "\n",
        "          pred=model(X)\n",
        "          pred_win=model_win(X)\n",
        "\n",
        "          loss=CELoss(pred,y.to(device))\n",
        "          loss_win=CELoss(pred_win,y.to(device))\n",
        "          running_loss+=loss.item()\n",
        "          running_loss_win+=loss_win.item()\n",
        "\n",
        "          # Get accuracy\n",
        "          for j in range(int(y.shape[0])):\n",
        "              i_class=y[j].detach().numpy().item()\n",
        "\n",
        "              class_counter[i_class]+=1\n",
        "              accuracy[i_class]+=(i_class==np.argmax(pred[j,:].detach().cpu().numpy()))\n",
        "              accuracy_win[i_class]+=(i_class==np.argmax(pred_win[j,:].detach().cpu().numpy()))\n",
        "\n",
        "          if batch_counter%log_loss==0:\n",
        "              # print things\n",
        "              print(\"Batch_Counter: \", batch_counter)\n",
        "\n",
        "              # update loss trace\n",
        "              plot_val_loss[loss_counter]=running_loss\n",
        "              plot_val_loss_win[loss_counter]=running_loss_win\n",
        "              loss_counter+=1\n",
        "\n",
        "              running_loss=0\n",
        "              running_loss_win=0\n",
        "\n",
        "  # Plot val loss\n",
        "  plt.figure(3)\n",
        "  plt.plot(plot_val_loss,label='conv')\n",
        "  plt.plot(plot_val_loss_win,label='conv_win')\n",
        "  plt.title('Val Losses')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.savefig(os.path.join(\"/save_dir\", 'val_loss_cifar100_all_win_wd_'+str(n_layers)+'_layers_'+str(None)+'.pdf'), bbox_inches='tight')\n",
        "\n",
        "  # Print accuracies\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "  print(\"Accuracy_Win: \", accuracy_win)\n",
        "  print(\"class_counter: \", class_counter)\n",
        "  print(\"Accuracy_percentage: \", accuracy.sum()/class_counter.sum()*100)\n",
        "  print(\"Accuracy_win_percentage: \", accuracy_win.sum()/class_counter.sum()*100)\n",
        "\n",
        "  # Save model + losses\n",
        "  torch.save({'state_dict': model.state_dict(), 'state_dict_win': model_win.state_dict(), 'training_loss': plot_loss, 'training_loss_win': plot_loss_win, 'val_loss': plot_val_loss, 'val_loss_win': plot_val_loss_win, 'accuracy': accuracy, 'accuracy_win': accuracy_win, 'class_counter': class_counter}, os.path.join(\"/save_dir\", 'model_cifar100_all_win_wd_'+str(n_layers)+'_layers_'+str(None)+'.pth'))\n",
        "  n_layers+=1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "671_testing_cifar100.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}